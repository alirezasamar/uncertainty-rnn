\documentclass{utmthesis}
\usepackage{graphicx}
\usepackage{url} 
\usepackage[pages=some]{background}
\usepackage{algorithm,algorithmic}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{cite}


\begin{document}

% Required information
\title{Uncertainty in Recurrent Neural Networks}
\author{Alireza Samar}
\degree{Master of Philosophy}
\specialization{Machine Learning}
\intakeyear{2016}
\faculty{Advanced Informatics School}
\titledate{April 2017}
\award{4}
% Options for Award 
% 1. Bachelor Degree Project Report
% 2. Master's Project Report (By course work)
% 3. Master's Dissertation (By course work and research)
% 4. Master's Thesis (By research)
% 5. Doctor of Philosophy Thesis
% 6. Other PhD Thesis
% 7. Generic PhD Thesis
% 8. Thesis Proposal
\superone{Dr. Siti Sophiayati Yuhaniz}
%\supertwo{M.Y. Other Supervisor}
%\superthree{Third SV}
%\superfour{Fourth SV}
%\superfive{Fifth SV}

% Option for two-page printing
\newgeometry{top=2.5cm,left=4cm,right=2.5cm,bottom=2.5cm,twoside}

% Option to add watermark page
% Comment for final version	
\backgroundsetup{scale=1,angle=0,opacity=.1,hshift=0.25in,vshift=-0.5in,contents={\includegraphics[width=5cm]{figs/utm02.jpg}}}
% \watermarkpage

% Mandatory pages
%\coverpage
%\superpage
%\certification
%\frontmatter
\maketitle
%\declaration

%\begin{dedication}
%Dedication\
%\end{dedication}

%\begin{acknowledgement}
%Acknowledgement
%\end{acknowledgement}

\begin{abstract}
Recurrent neural networks (RNN), and especially Deep RNNs have outperformed in various fields from computer vision, and language processing to physics, biology, and manufacturing. This means the deep or multi-layer architecture of neural networks are being extensively used in these fields; for instance convolutional neural networks (CNN) as image processing tools, and recurrent neural networks (RNN) as sequence processing model various from language modeling to image captioning.

In traditional sciences fields such as physics and biology, analysis of model uncertainty is crucial. Nowadays, the control of critical systems is being handed to machine learning-based systems that could affect our day-to-day life directly, but the question is "what should these systems do with high uncertainty in output?" As a solution, by having model confidence, uncertain outputs can be treated as the special case by a human to make the decision.

This work aims to propose a novel thechnique and develop tools to measure uncertainty estimates by adoption of Bayes by Backprop to the given network, especially in deep recurrent neural networks. The performance of proposed technique in this work will be extensively evaluated with widely studied benchmark.

\end{abstract}

%\begin{abstrak}
%Ini adalah abstrak Bahasa Melayu
%\end{abstrak}

\tableofcontents
\listoftables
\listoffigures

%List of abbreviation 
\listofabbre
\addabbre{ANN}{Artificial Neural Network}
\addabbre{NN}{Neural Network}
\addabbre{BNN}{Bayesian Neural Network}
\addabbre{RNN}{Recurrent Neural Network}
\addabbre{BBB}{Bayes by Backprop}
\addabbre{CNN}{Convolutional Neural Network}
\addabbre{KL}{Kullback-Leibler}
\addabbre{GP}{Gaussian Process}
\addabbre{MC}{Monte Carlo}
\addabbre{VI}{Variational Inference}
\addabbre{MCMC}{Markov Chain Monte Carlo}
\addabbre{LSTM}{Long Short-Term Memory}
\addabbre{SRT}{Stochastic Regularisation Technique (such as dropout)}
\addabbre{i.e.}{Id est (“it is”)}
\addabbre{w.r.t.}{With respect to}

%List of symbols 
\listofsymbols
\addsymbol{$A$}{A rolled NN}
\addsymbol{\textbf{A}}{Matrix}
\addsymbol{a}{vector}
\addsymbol{$t$}{Steps/Length of RNN}
\addsymbol{$x_t$}{Input value}
\addsymbol{$\eta$}{Trained parameter}
\addsymbol{$c$}{Internal core sate}
\addsymbol{$h$}{Exposed sate}
\addsymbol{$i_t$}{Input gate}
\addsymbol{$f_t$}{Forget gate}
\addsymbol{$h_t$}{Exposed sate}
\addsymbol{$W$}{Weights (biases)}

%List of appendices
%\listofappendices

\onehalfspacing
\mainmatter

\include{Chapters/ch1}
\include{Chapters/ch2}
\include{Chapters/ch3}
\include{Chapters/ch4}
%\include{Chapters/ch5}
%\include{Chapters/ch6}

\bibliographystyle{utmthesis-numbering}
\bibliography{reference}

%\appendix
%\chapter{Do not use long titles.}
%\chapter{Pseudo-codes}
%\chapter{Time-series Results}

%This is required to make List of Appendices possible. Remove when have no appendix.
%\endmatter
\end{document}
